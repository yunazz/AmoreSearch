import os
import asyncio
import chromadb
import json
from langchain.chat_models import ChatOpenAI
from langchain.agents import AgentType, initialize_agent
from langchain.tools import tool
from langchain.schema import SystemMessage
from langchain.prompts import PromptTemplate
from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
from dotenv import load_dotenv
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
LLM_MODEL = "gpt-4"
COLLECTION_NAME_POST = "posts"
COLLECTION_NAME_BRAND = "brand"
COLLECTION_NAME_COSMETIC = "cosmetic"
COLLECTION_NAME_INGREDIENT = "ingredient"
COLLECTION_NAME_LAW = "law"

def get_fresh_llm():
    """ë§¤ë²ˆ ìƒˆë¡œìš´ LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ ì´ˆê¸°í™”"""
    return ChatOpenAI(model_name=LLM_MODEL, openai_api_key=OPENAI_API_KEY, temperature=0, cache=False)

embedding_function = OpenAIEmbeddings(
    base_url="https://76mqtyy2wie64y-10050.proxy.runpod.net/v1",
    model="multilingual-e5-large",
    api_key="team3",
    tiktoken_enabled=False,
    embedding_ctx_length=502
)

client = chromadb.HttpClient(host="3.35.104.197", port=10090)

collections = {
    "post": client.get_collection(COLLECTION_NAME_POST),
    "brand": client.get_collection(COLLECTION_NAME_BRAND),
    "cosmetic": client.get_collection(COLLECTION_NAME_COSMETIC),
    "ingredient": client.get_collection(COLLECTION_NAME_INGREDIENT),
    # "law": client.get_collection(COLLECTION_NAME_LAW),
}

classification_prompt = PromptTemplate(
    template="""ë‹¹ì‹ ì€ ì•„ëª¨ë ˆí¼ì‹œí”½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì„ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
    
    ì•„ëª¨ë ˆí¼ì‹œí”½ì˜ ìì‚¬ë¸Œëœë“œ: 
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ì„¤í™”ìˆ˜, ë¸Œëœë“œëª…(ì˜ì–´) sulwhasoo
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ë¼ë„¤ì¦ˆ, ë¸Œëœë“œëª…(ì˜ì–´) laneige
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ì´ë‹ˆìŠ¤í”„ë¦¬, ë¸Œëœë“œëª…(ì˜ì–´) innisfree
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ì—ì´í”¼ë·°í‹°, ë¸Œëœë“œëª…(ì˜ì–´) ap
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):í—¤ë¼, ë¸Œëœë“œëª…(ì˜ì–´) hera
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):í”„ë¦¬ë©”ë¼, ë¸Œëœë“œëª…(ì˜ì–´) primera
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ì•„ì´ì˜¤í˜, ë¸Œëœë“œëª…(ì˜ì–´) iope
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ë§ˆëª½ë“œ, ë¸Œëœë“œëª…(ì˜ì–´) mamonde
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):í•œìœ¨, ë¸Œëœë“œëª…(ì˜ì–´) hanyul
    ì¹´í…Œê³ ë¦¬: MEDICAL_BEAUTY, ë¸Œëœë“œëª…(í•œê¸€):ì—ìŠ¤íŠ¸ë¼, ë¸Œëœë“œëª…(ì˜ì–´) aestura
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ì—ìŠ¤ì˜ì•„, ë¸Œëœë“œëª…(ì˜ì–´) espoir
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ì—ë›°ë“œ, ë¸Œëœë“œëª…(ì˜ì–´) etude
    ì¹´í…Œê³ ë¦¬: HAIR, ë¸Œëœë“œëª…(í•œê¸€):ë ¤, ë¸Œëœë“œëª…(ì˜ì–´) ryo
    ì¹´í…Œê³ ë¦¬: HAIR, ë¸Œëœë“œëª…(í•œê¸€):ë¯¸ìŸì„¼, ë¸Œëœë“œëª…(ì˜ì–´) mise en scene
    ì¹´í…Œê³ ë¦¬: HAIR, ë¸Œëœë“œëª…(í•œê¸€):ë¼ë³´ì—ì´ì¹˜, ë¸Œëœë“œëª…(ì˜ì–´) laboh
    ì¹´í…Œê³ ë¦¬: HAIR, ë¸Œëœë“œëª…(í•œê¸€):ì•„ìœ¤ì±„, ë¸Œëœë“œëª…(ì˜ì–´) ayunche
    ì¹´í…Œê³ ë¦¬: HAIR, ë¸Œëœë“œëª…(í•œê¸€):ì•„ëª¨ìŠ¤í”„ë¡œí˜ì…”ë„, ë¸Œëœë“œëª…(ì˜ì–´) amos professional
    ì¹´í…Œê³ ë¦¬: HAIR, ë¸Œëœë“œëª…(í•œê¸€):ë¡±í…Œì´í¬, ë¸Œëœë“œëª…(ì˜ì–´) longtake
    ì¹´í…Œê³ ë¦¬: BODY, ë¸Œëœë“œëª…(í•œê¸€):ì¼ë¦¬ìœ¤, ë¸Œëœë“œëª…(ì˜ì–´) illiyoon
    ì¹´í…Œê³ ë¦¬: BODY, ë¸Œëœë“œëª…(í•œê¸€):í•´í”¼ë°”ìŠ¤, ë¸Œëœë“œëª…(ì˜ì–´) happybath
    ì¹´í…Œê³ ë¦¬: BODY, ë¸Œëœë“œëª…(í•œê¸€):ìŠ¤í‚¨ìœ , ë¸Œëœë“œëª…(ì˜ì–´) skin u
    ì¹´í…Œê³ ë¦¬: ORAL_CARE, ë¸Œëœë“œëª…(í•œê¸€):ë©”ë””ì•ˆ, ë¸Œëœë“œëª…(ì˜ì–´) median
    ì¹´í…Œê³ ë¦¬: ORAL_CARE, ë¸Œëœë“œëª…(í•œê¸€):ì  í‹°ìŠ¤íŠ¸, ë¸Œëœë“œëª…(ì˜ì–´) gentist
    ì¹´í…Œê³ ë¦¬: PERFUME, ë¸Œëœë“œëª…(í•œê¸€):êµ¬ë”¸, ë¸Œëœë“œëª…(ì˜ì–´) goutal
    ì¹´í…Œê³ ë¦¬: INNER_BEAUTY, ë¸Œëœë“œëª…(í•œê¸€):ë°”ì´íƒˆë·°í‹°, ë¸Œëœë“œëª…(ì˜ì–´) vital beauty
    ì¹´í…Œê³ ë¦¬: TEA_CULTURE, ë¸Œëœë“œëª…(í•œê¸€):ì˜¤ì„¤ë¡, ë¸Œëœë“œëª…(ì˜ì–´) osulloc
    ì¹´í…Œê³ ë¦¬: BEAUTY_DEVICE, ë¸Œëœë“œëª…(í•œê¸€):ë©”ì´í¬ì˜¨, ë¸Œëœë“œëª…(ì˜ì–´) makeon
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ì˜¤ë”§ì„¸ì´, ë¸Œëœë“œëª…(ì˜ì–´) odyssey
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):ë¹„ë ˆë””, ë¸Œëœë“œëª…(ì˜ì–´) bready
    ì¹´í…Œê³ ë¦¬: BEAUTY_CARE, ë¸Œëœë“œëª…(í•œê¸€):í™€ë¦¬ì¶”ì–¼, ë¸Œëœë“œëª…(ì˜ì–´) holitual

    ì§ˆë¬¸: "{question}"
    
    ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬:
    - "ingredient" (ì„±ë¶„, í™”ì¥í’ˆ ê¸°ëŠ¥ ê´€ë ¨ ì§ˆë¬¸)
    - "amore_cosmetic" (ìì‚¬ í™”ì¥í’ˆ ê²€ìƒ‰ ì§ˆë¬¸)
    - "other_cosmetic" (íƒ€ì‚¬ í™”ì¥í’ˆ ê²€ìƒ‰ ì§ˆë¬¸)
    - "cosmetic" (ë¸Œëœë“œ êµ¬ë³„ ì—†ì´ í™”ì¥í’ˆì— ê´€í•œ ì§ˆë¬¸ì§ˆë¬¸)
    - "company" (íšŒì‚¬ ì „ë°˜ì ì¸ ì§ˆë¬¸)
    - "news" (ìµœì‹  ë‰´ìŠ¤ë‚˜ ê¸°ì‚¬ ê´€ë ¨ ì§ˆë¬¸)

    ë°˜ë“œì‹œ ìœ„ì˜ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    
    ìì‚¬ 
    ì¹´í…Œê³ ë¦¬:""",
    input_variables=["question"],
)

@tool
def classify_question(question: str) -> str:
    """ì§ˆë¬¸ì„ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    llm = get_fresh_llm() 
    response = llm.invoke(classification_prompt.format(question=question))
    return response.content.strip().replace('"', '')

@tool
def multi_collection_retriever(input_data: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ChromaDB ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ í›„ JSON í˜•ì‹ì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    input_dataëŠ” JSON ë¬¸ìì—´ì´ë©°, 'query'ì™€ 'category'ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    data = json.loads(input_data) 
    query = data["query"]
    category = data["category"]  

    retrieved_docs = {} 
    query_embedding = embedding_function.embed_query(query)

    print(f"ê²€ìƒ‰í•  ì¹´í…Œê³ ë¦¬: {category}")

    search_collections = []
    metadata_filter = None 

    if category == "ingredient":
        search_collections = ["ingredient", "cosmetic"]
    elif category == "amore_cosmetic":
        search_collections = ["cosmetic"]
        metadata_filter = {"scope": "ìì‚¬"}
    elif category == "other_cosmetic":
        search_collections = ["cosmetic"]
        metadata_filter = {"scope": "íƒ€ì‚¬"} 
    elif category == "cosmetic":
        search_collections = ["cosmetic", "ingredient"] 
    elif category == "company":
        search_collections = ["brand", "posts"]
    elif category == "news":
        search_collections = ["posts"]

    print(f"ê²€ìƒ‰í•  ì»¬ë ‰ì…˜: {search_collections}")
    print(f"ì ìš©í•  ë©”íƒ€ë°ì´í„° í•„í„°: {metadata_filter}")

    for collection_name in search_collections:
        if metadata_filter:
            results = collections[collection_name].query(
                query_embeddings=[query_embedding], 
                n_results=5,
                where=metadata_filter 
            )
        else:
            results = collections[collection_name].query(
                query_embeddings=[query_embedding], 
                n_results=5
            )

        retrieved_docs[collection_name] = [
            {"content": results['documents'][0][i], "metadata": results['metadatas'][0][i]}
            for i in range(len(results['ids'][0]))
        ]

    return json.dumps(retrieved_docs, ensure_ascii=False)

response_prompt = PromptTemplate(
    template="""ë‹¹ì‹ ì€ ì•„ëª¨ë ˆí¼ì‹œí”½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ì§ˆë¬¸: {question}

    ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.

    {context}

    ë‹µë³€:""",
    input_variables=["question", "context"],
)

@tool
def generate_response(input_data: str) -> str:
    """
    ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    input_dataëŠ” JSON í˜•ì‹ìœ¼ë¡œ ì „ë‹¬ë˜ë©°, 'question'ê³¼ 'retrieved_docs'ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    """
    llm = get_fresh_llm() 
    data = json.loads(input_data)
    question = data["question"]
    retrieved_docs = data["retrieved_docs"]

    context_sections = []
    for collection_name, docs in retrieved_docs.items():
        if docs:
            doc_texts = "\n".join([doc["content"] for doc in docs])
            context_sections.append(f"### {collection_name.upper()} ê´€ë ¨ ì •ë³´ ###\n{doc_texts}")

    context = "\n\n".join(context_sections)[:7000]

    response = llm.invoke(response_prompt.format(question=question, context=context))
    return response.content.strip()

tools = [classify_question, multi_collection_retriever, generate_response]

agent = initialize_agent(
    tools=tools,
    llm=get_fresh_llm(), 
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

def agentic_rag_chain(question: str):
    category = classify_question(question) 
    retrieved_docs = multi_collection_retriever(json.dumps({"query": question, "category": category}, ensure_ascii=False)) 
    response = generate_response(json.dumps({"question": question, "retrieved_docs": json.loads(retrieved_docs)}, ensure_ascii=False))

    return {
        "question": question,
        "category": category,
        "response": response,
        "retrieved_docs": json.loads(retrieved_docs)
    }


class AISearch:
    @staticmethod
    async def search(question: str):
        llm = ChatOpenAI(model=LLM_MODEL, openai_api_key=OPENAI_API_KEY, model_kwargs={"stream": True})
        
        async for chunk in llm.astream(question):
            if chunk.content:
                yield chunk.content  
            await asyncio.sleep(0.1)
    

class IntegrationSearch:
    @staticmethod
    async def search(question: str):
        response = agentic_rag_chain(question)

        for chunk in response.split(" "):  # ğŸ”¹ ë‹¨ì–´ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡
            yield chunk + " "
            await asyncio.sleep(0.1)